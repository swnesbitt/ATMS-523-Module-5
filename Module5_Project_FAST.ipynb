{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79fbfa3f",
   "metadata": {},
   "source": [
    "# ATMS 523 Module 5 Project (FAST Version)\n",
    "\n",
    "This notebook implements the radar_parameters regression analysis following the assignment prompt.\n",
    "It includes:\n",
    "- Baseline computation (Z–R relation)\n",
    "- Multiple Linear Regression\n",
    "- Polynomial Regression (0–9 degree, 7-fold CV)\n",
    "- Random Forest (optimized grid search)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7228a90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'Baseline (Z=200R^1.6)', 'R2_train': 0.2755506634712219, 'RMSE_train': np.float64(7.143949773870337), 'R2_test': 0.3566429018974304, 'RMSE_test': np.float64(7.1893164951531014)}\n",
      "{'model': 'Linear Regression', 'R2_train': 0.8271994590759277, 'RMSE_train': np.float64(3.4890477618782993), 'R2_test': 0.8410272002220154, 'RMSE_test': np.float64(3.573740175653319)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:516: FitFailedWarning: \n",
      "7 fits failed out of a total of 70.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/pipeline.py\", line 655, in fit\n",
      "    Xt = self._fit(X, y, routed_params, raw_params=params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/pipeline.py\", line 589, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/joblib/memory.py\", line 326, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/pipeline.py\", line 1540, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 897, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/sklearn/preprocessing/_polynomial.py\", line 313, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Setting degree to zero and include_bias to False would result in an empty output array.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1135: UserWarning: One or more of the test scores are non-finite: [          nan    0.99022922    0.99808323    0.97948911  -17.2836667\n",
      "  -51.72750223 -154.81866284  -40.92580842 -154.34255258   -2.02075215]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'Polynomial Regression (deg=2)', 'R2_train': 0.8905119895935059, 'RMSE_train': np.float64(2.7772672618522156), 'R2_test': 0.9930459260940552, 'RMSE_test': np.float64(0.7474483156995063)}\n",
      "{'model': 'Random Forest (fast)', 'R2_train': 0.9877867966913689, 'RMSE_train': np.float64(0.9275752809371336), 'R2_test': 0.9779099738301961, 'RMSE_test': np.float64(1.332170018059722)}\n",
      "\n",
      "Final Model Comparison:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>R2_train</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>R2_test</th>\n",
       "      <th>RMSE_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline (Z=200R^1.6)</td>\n",
       "      <td>0.275551</td>\n",
       "      <td>7.143950</td>\n",
       "      <td>0.356643</td>\n",
       "      <td>7.189316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>0.827199</td>\n",
       "      <td>3.489048</td>\n",
       "      <td>0.841027</td>\n",
       "      <td>3.573740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Polynomial Regression (deg=2)</td>\n",
       "      <td>0.890512</td>\n",
       "      <td>2.777267</td>\n",
       "      <td>0.993046</td>\n",
       "      <td>0.747448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest (fast)</td>\n",
       "      <td>0.987787</td>\n",
       "      <td>0.927575</td>\n",
       "      <td>0.977910</td>\n",
       "      <td>1.332170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           model  R2_train  RMSE_train   R2_test  RMSE_test\n",
       "0          Baseline (Z=200R^1.6)  0.275551    7.143950  0.356643   7.189316\n",
       "1              Linear Regression  0.827199    3.489048  0.841027   3.573740\n",
       "2  Polynomial Regression (deg=2)  0.890512    2.777267  0.993046   0.747448\n",
       "3           Random Forest (fast)  0.987787    0.927575  0.977910   1.332170"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, warnings, gc, numpy as np, pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# System and warnings optimization\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# === Load dataset ===\n",
    "df = pd.read_csv('radar_parameters.csv')\n",
    "df = df.rename(columns={\n",
    "    'Zh (dBZ)': 'Zh', 'Zdr (dB)': 'Zdr', 'Ldr (dB)': 'Ldr',\n",
    "    'Kdp (deg km-1)': 'Kdp', 'Ah (dBZ/km)': 'Ah', 'Adr (dB/km)': 'Adp',\n",
    "    'R (mm/hr)': 'R'\n",
    "})\n",
    "df = df.dropna().astype('float32')\n",
    "\n",
    "FEATURES = ['Zh','Zdr','Ldr','Kdp','Ah','Adp']\n",
    "TARGET = 'R'\n",
    "X, y = df[FEATURES].values, df[TARGET].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# === Baseline ===\n",
    "def baseline_predict(Zh):\n",
    "    Z_lin = 10 ** (Zh / 10.0)\n",
    "    return (Z_lin / 200.0) ** (1.0 / 1.6)\n",
    "\n",
    "y_pred_train_base = baseline_predict(X_train[:,0])\n",
    "y_pred_test_base  = baseline_predict(X_test[:,0])\n",
    "baseline_results = {\n",
    "    'model': 'Baseline (Z=200R^1.6)',\n",
    "    'R2_train': r2_score(y_train, y_pred_train_base),\n",
    "    'RMSE_train': rmse(y_train, y_pred_train_base),\n",
    "    'R2_test': r2_score(y_test, y_pred_test_base),\n",
    "    'RMSE_test': rmse(y_test, y_pred_test_base)\n",
    "}\n",
    "print(baseline_results)\n",
    "\n",
    "# === Linear Regression ===\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "y_pred_train_lr, y_pred_test_lr = lr.predict(X_train), lr.predict(X_test)\n",
    "lr_results = {\n",
    "    'model': 'Linear Regression',\n",
    "    'R2_train': r2_score(y_train, y_pred_train_lr),\n",
    "    'RMSE_train': rmse(y_train, y_pred_train_lr),\n",
    "    'R2_test': r2_score(y_test, y_pred_test_lr),\n",
    "    'RMSE_test': rmse(y_test, y_pred_test_lr)\n",
    "}\n",
    "print(lr_results)\n",
    "\n",
    "# === Polynomial Regression (0–9 degrees, fast CV) ===\n",
    "N_small = min(2000, len(X_train))\n",
    "idx = np.random.default_rng(42).choice(len(X_train), N_small, replace=False)\n",
    "X_small, y_small = X_train[idx], y_train[idx]\n",
    "\n",
    "poly_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(include_bias=False)),\n",
    "    ('lr', LinearRegression())\n",
    "])\n",
    "param_grid = {'poly__degree': list(range(0, 10))}\n",
    "cv = KFold(n_splits=7, shuffle=True, random_state=42)\n",
    "gs_poly = GridSearchCV(poly_pipe, param_grid, scoring='r2', cv=cv, n_jobs=1, verbose=0)\n",
    "gs_poly.fit(X_small, y_small)\n",
    "best_poly = gs_poly.best_estimator_\n",
    "best_d = gs_poly.best_params_['poly__degree']\n",
    "y_pred_train_poly = best_poly.predict(X_train)\n",
    "y_pred_test_poly = best_poly.predict(X_test)\n",
    "poly_results = {\n",
    "    'model': f'Polynomial Regression (deg={best_d})',\n",
    "    'R2_train': r2_score(y_train, y_pred_train_poly),\n",
    "    'RMSE_train': rmse(y_train, y_pred_train_poly),\n",
    "    'R2_test': r2_score(y_test, y_pred_test_poly),\n",
    "    'RMSE_test': rmse(y_test, y_pred_test_poly)\n",
    "}\n",
    "print(poly_results)\n",
    "\n",
    "# === Random Forest (very light HalvingGridSearchCV) ===\n",
    "param_rf = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [10, 30, None],\n",
    "    'max_features': ['sqrt'],\n",
    "    'min_samples_leaf': [1, 4],\n",
    "    'min_samples_split': [2, 5],\n",
    "}\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=1, max_samples=0.6)\n",
    "hgs = HalvingGridSearchCV(rf, param_rf, scoring='r2', cv=cv, resource='n_estimators', min_resources=10, max_resources=400, factor=4, n_jobs=1, verbose=0)\n",
    "N_rf = min(1000, len(X_train))\n",
    "idx_rf = np.random.default_rng(42).choice(len(X_train), N_rf, replace=False)\n",
    "hgs.fit(X_train[idx_rf], y_train[idx_rf])\n",
    "\n",
    "\n",
    "params = {k: v for k, v in hgs.best_params_.items() if k != 'n_estimators'}\n",
    "\n",
    "best_rf = RandomForestRegressor(\n",
    "    **params,\n",
    "    n_estimators=400,      \n",
    "    random_state=42,\n",
    "    n_jobs=1,\n",
    "    max_samples=0.6\n",
    ")\n",
    "\n",
    "\n",
    "best_rf.fit(X_train, y_train)\n",
    "y_pred_train_rf, y_pred_test_rf = best_rf.predict(X_train), best_rf.predict(X_test)\n",
    "rf_results = {\n",
    "    'model': 'Random Forest (fast)',\n",
    "    'R2_train': r2_score(y_train, y_pred_train_rf),\n",
    "    'RMSE_train': rmse(y_train, y_pred_train_rf),\n",
    "    'R2_test': r2_score(y_test, y_pred_test_rf),\n",
    "    'RMSE_test': rmse(y_test, y_pred_test_rf)\n",
    "}\n",
    "print(rf_results)\n",
    "\n",
    "# === Summary ===\n",
    "summary = pd.DataFrame([baseline_results, lr_results, poly_results, rf_results])\n",
    "print('\\nFinal Model Comparison:')\n",
    "display(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dea4de-ed39-45c6-befc-22610940b355",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

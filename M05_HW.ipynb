{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8165b570",
   "metadata": {},
   "source": [
    "# ATMS 523\n",
    "\n",
    "## Module 5 Project\n",
    "### Sarah Henry\n",
    "\n",
    "Fork this repository, and submit this code as a pull request back to GitHub by the date and time listed in Canvas.\n",
    "\n",
    "For this assignment, use the dataset called `radar_parameters.csv` provided in the GitHub repository in the folder `homework`.\n",
    "\n",
    "## Dataset Description\n",
    "\n",
    "The training data consists of polarimetric radar parameters calculated from a disdrometer (an instrument that measures rain drop sizes, shapes, and rainfall rate) measurements from several years in Huntsville, Alabama. A model called `pytmatrix` is used to calculate polarimetric radar parameters from the droplet observations, which can be used as a way to compare what a remote sensing instrument would see and rainfall.\n",
    "\n",
    "## Data columns\n",
    "\n",
    "Features (radar measurements):\n",
    "\n",
    "`Zh` - radar reflectivity factor (dBZ) - use the formula $dBZ = 10\\log_{10}(Z)$\n",
    "\n",
    "`Zdr` - differential reflectivity\n",
    "\n",
    "`Ldr` - linear depolarization ratio\n",
    "\n",
    "`Kdp` - specific differential phase\n",
    "\n",
    "`Ah` - specific attenuation\n",
    "\n",
    "`Adp` - differential attenuation\n",
    "\n",
    "Target :\n",
    "\n",
    "`R` - rain rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55418bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             RocCurveDisplay, PrecisionRecallDisplay,\n",
    "                             mean_squared_error, r2_score)\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17280a7",
   "metadata": {},
   "source": [
    "1. Split the data into a 70-30 split for training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "456dfef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13278 5691\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv(\"./homework/radar_parameters.csv\")\n",
    "target = [\"R (mm/hr)\"]\n",
    "predictors = df.drop(columns=\"R (mm/hr)\").columns.tolist()\n",
    "\n",
    "# split data\n",
    "X = df[predictors].values\n",
    "y = df[target].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "print(len(X_train), len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63636e54",
   "metadata": {},
   "source": [
    "2. Using the split created in (1), train a multiple linear regression dataset using the training dataset, and validate it using the testing dataset.  Compare the $R^2$ and root mean square errors of model on the training and testing sets to a baseline prediction of rain rate using the formula $Z = 200 R^{1.6}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dc4fce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation:\n",
      "R^2 train: 0.9888357865565246, R^2 test: 0.9868605147786397\n",
      "RMSE train: 0.9146705347774785, RMSE test: 0.9583373917841838\n",
      "\n",
      "comparison to baseline:\n",
      "R^2 train: 0.3325181229088806, R^2 test: 0.22661047398943468\n",
      "RMSE train: 7.072457766822083, RMSE test: 7.3523877227693095\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# validate\n",
    "def rmse(a, b):\n",
    "    return np.sqrt(mean_squared_error(a, b))\n",
    "\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "rmse_train = rmse(y_train, y_train_pred)\n",
    "rmse_test = rmse(y_test, y_test_pred)\n",
    "\n",
    "print(\"validation:\")\n",
    "print(f\"R^2 train: {r2_train}, R^2 test: {r2_test}\")\n",
    "print(f\"RMSE train: {rmse_train}, RMSE test: {rmse_test}\")\n",
    "\n",
    "# compare to baseline\n",
    "R = 10 ** (df[\"Zh (dBZ)\"] / 10)\n",
    "Z_baseline = (R / 200) ** (1 / 1.6)\n",
    "\n",
    "Z_train = X_train[:, predictors.index(\"Zh (dBZ)\")]\n",
    "Z_test = X_test[:, predictors.index(\"Zh (dBZ)\")]\n",
    "\n",
    "Z_baseline_train = (10 ** (Z_train / 10) / 200) ** (1 / 1.6)\n",
    "Z_baseline_test = (10 ** (Z_test / 10) / 200) ** (1 / 1.6)\n",
    "\n",
    "r2_base_train = r2_score(y_train, Z_baseline_train)\n",
    "r2_base_test = r2_score(y_test, Z_baseline_test)\n",
    "\n",
    "rmse_base_train = rmse(y_train, Z_baseline_train)\n",
    "rmse_base_test = rmse(y_test, Z_baseline_test)\n",
    "\n",
    "print(\"\\ncomparison to baseline:\")\n",
    "print(f\"R^2 train: {r2_base_train}, R^2 test: {r2_base_test}\")\n",
    "print(f\"RMSE train: {rmse_base_train}, RMSE test: {rmse_base_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1f9edb",
   "metadata": {},
   "source": [
    "3. Repeat 1 doing a grid search over polynomial orders, using a grid search over orders 0-9, and use cross-validation of 7 folds.  For the best polynomial model in terms of $R^2$, does it outperform the baseline and the linear regression model in terms of $R^2$ and root mean square error?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5852baba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating degree 0...\n",
      "Evaluating degree 1...\n",
      "Evaluating degree 2...\n",
      "\n",
      "Best degree (CV R^2): 2\n",
      "Mean CV R^2 for best degree: 0.9989829546605608\n"
     ]
    }
   ],
   "source": [
    "def PolynomialRegression(degree=2, **kwargs):\n",
    "    include_bias = (degree == 0)\n",
    "    return make_pipeline(\n",
    "        PolynomialFeatures(degree, include_bias=include_bias),\n",
    "        LinearRegression(**kwargs)\n",
    "    )\n",
    "\n",
    "degrees = np.arange(0, 2+1)\n",
    "train_r2 = []\n",
    "val_r2 = []\n",
    "\n",
    "for d in degrees:\n",
    "    print(f\"Evaluating degree {d}...\")\n",
    "    model = PolynomialRegression(degree=d)\n",
    "    scores = cross_val_score(model, X_train, y_train.ravel(), cv=7, scoring='r2', n_jobs=-1)\n",
    "    val_r2.append(scores.mean())\n",
    "\n",
    "best_degree = degrees[np.argmax(val_r2)]\n",
    "print(f\"\\nBest degree (CV R^2): {best_degree}\")\n",
    "print(f\"Mean CV R^2 for best degree: {max(val_r2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d4184b",
   "metadata": {},
   "source": [
    "Output from all degrees 0-9:\n",
    "\n",
    "Best degree (CV R²): 2\n",
    "\n",
    "Mean CV R² for best degree: 0.999\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2cc1a4",
   "metadata": {},
   "source": [
    "4. Repeat 1 with a Random Forest Regressor, and perform a grid_search on the following parameters:\n",
    "   \n",
    "   ```python\n",
    "   param_grid = {\n",
    "    \"bootstrap\": [True, False],\n",
    "    \"max_depth\": [10, 100],\n",
    "    \"max_features\": [\"sqrt\", 1.0],  \n",
    "    \"min_samples_leaf\": [1, 4],\n",
    "    \"min_samples_split\": [2, 10],\n",
    "    \"n_estimators\": [200, 1000]}\n",
    "   ```\n",
    "  Can you beat the baseline, or the linear regression, or best polynomial model with the best optimized Random Forest Regressor in terms of $R^2$ and root mean square error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7e9b6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best RF params:\n",
      "{'bootstrap': True, 'max_depth': 14, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 119}\n",
      "\n",
      "Random Forest Regressor Performance:\n",
      "R^2 train: 0.996, R^2 test: 0.970\n",
      "RMSE train: 0.547, RMSE test: 1.459\n"
     ]
    }
   ],
   "source": [
    "# param_grid = {\n",
    "#     \"bootstrap\": [True, False],\n",
    "#     \"max_depth\": [10, 100],\n",
    "#     \"max_features\": [\"sqrt\", 1.0],\n",
    "#     \"min_samples_leaf\": [1, 4],\n",
    "#     \"min_samples_split\": [2, 10],\n",
    "#     \"n_estimators\": [200, 1000]\n",
    "# }\n",
    "\n",
    "# rf = RandomForestRegressor(random_state=0)\n",
    "\n",
    "# grid_rf = GridSearchCV(\n",
    "#     estimator=rf,\n",
    "#     param_grid=param_grid,\n",
    "#     cv=7,\n",
    "#     scoring='r2',\n",
    "#     n_jobs=-1,\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# grid_rf.fit(X_train, y_train.ravel())\n",
    "\n",
    "# best_rf = grid_rf.best_estimator_\n",
    "# print(\"Best RF params:\")\n",
    "# print(grid_rf.best_params_)\n",
    "\n",
    "# y_train_rf = best_rf.predict(X_train)\n",
    "# y_test_rf = best_rf.predict(X_test)\n",
    "\n",
    "# r2_rf_train = r2_score(y_train, y_train_rf)\n",
    "# r2_rf_test = r2_score(y_test, y_test_rf)\n",
    "# rmse_rf_train = rmse(y_train, y_train_rf)\n",
    "# rmse_rf_test = rmse(y_test, y_test_rf)\n",
    "\n",
    "# print(\"\\nRandom Forest Regressor Performance:\")\n",
    "# print(f\"R^2 train: {r2_rf_train}, R^2 test: {r2_rf_test}\")\n",
    "# print(f\"RMSE train: {rmse_rf_train}, RMSE test: {rmse_rf_test}\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "rf = RandomForestRegressor(random_state=0)\n",
    "\n",
    "param_dist = {\n",
    "    \"bootstrap\": [True],\n",
    "    \"max_depth\": randint(5, 30),           # smaller trees = faster\n",
    "    \"max_features\": [\"sqrt\"],\n",
    "    \"min_samples_leaf\": randint(1, 4),\n",
    "    \"min_samples_split\": randint(2, 5),\n",
    "    \"n_estimators\": randint(50, 150)       # fewer trees = much faster\n",
    "}\n",
    "\n",
    "rand_rf = RandomizedSearchCV(\n",
    "    rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10, # fewer combinations\n",
    "    cv=3, # fewer folds\n",
    "    scoring='r2',\n",
    "    n_jobs=-1,\n",
    "    random_state=0,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "rand_rf.fit(X_train, y_train.ravel())\n",
    "\n",
    "best_rf = rand_rf.best_estimator_\n",
    "print(\"Best RF params:\")\n",
    "print(rand_rf.best_params_)\n",
    "\n",
    "y_train_rf = best_rf.predict(X_train)\n",
    "y_test_rf = best_rf.predict(X_test)\n",
    "\n",
    "r2_rf_train = r2_score(y_train, y_train_rf)\n",
    "r2_rf_test = r2_score(y_test, y_test_rf)\n",
    "rmse_rf_train = rmse(y_train, y_train_rf)\n",
    "rmse_rf_test = rmse(y_test, y_test_rf)\n",
    "\n",
    "print(\"\\nRandom Forest Regressor Performance:\")\n",
    "print(f\"R^2 train: {r2_rf_train:.3f}, R^2 test: {r2_rf_test:.3f}\")\n",
    "print(f\"RMSE train: {rmse_rf_train:.3f}, RMSE test: {rmse_rf_test:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe52c1d",
   "metadata": {},
   "source": [
    "No, the random forest model doesn't beat the 2-degree polynomial model. I would guess that there might be some overfitting with the 2-degree polynomial model but since the degree is low and it cross validates well, it looks solid. Despite that though, the random forest model is still robust and if I were able to run the whole code (it was taking wayyy too long) it might improve just a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19045e2b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
